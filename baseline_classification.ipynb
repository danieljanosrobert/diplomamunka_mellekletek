{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gyakran változtatott konstansok\n",
    "\n",
    "# Stop word-ök használata\n",
    "USE_STOPWORDS = True\n",
    "\n",
    "# Stemmelés használata\n",
    "USE_STEM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Importok\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Konstansok\n",
    "\n",
    "# Random seed-ek értéke\n",
    "SHUFFLE_RANDOM_STATE = 42\n",
    "TRAIN_RANDOM_STATE = 42\n",
    "SGD_RANDOM_STATE = 42\n",
    "\n",
    "# A program számára fontos fejlécek értéke az adatbázisban\n",
    "TEXT = 'Sentence'\n",
    "Y_HEADER = 'LABEL'\n",
    "\n",
    "# Az adatbázisban található értékek megfeleltetése a programban\n",
    "LABELS = {\n",
    "    \"NEG\": 0,\n",
    "    \"SEM\": 1,\n",
    "    \"POZ\": 2\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Szöveg feldolgozására alkalmas metódusok\n",
    "\n",
    "URL_RE = 'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}([-a-zA-Z0-9()@:%_+.~#?&/=]*)'\n",
    "WHITELIST_RE = '[^a-zA-Z0-9íÍöÖüÜóÓőŐúÚáÁéÉűŰ]'\n",
    "\n",
    "def cleanse(i):\n",
    "    \"\"\"\n",
    "    Adatbázisban szereplő dokumentumok megtisztítása az URL-ektől és a nem-alfanumerikus karakterektől.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    i: int\n",
    "        A tisztítandó dokumentumnak az indexe.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A megtisztított dokumentum.\n",
    "    \"\"\"\n",
    "\n",
    "    text = dataset[TEXT].iloc[i]\n",
    "    text = re.sub(URL_RE, ' ', text)\n",
    "    text = re.sub(WHITELIST_RE, ' ', text)\n",
    "    text = ' '.join([text.lower()])\n",
    "    return re.sub(' +', ' ', text)\n",
    "\n",
    "def delete_empty_rows(dataset):\n",
    "    \"\"\"\n",
    "    Az adatbázist megtisztítja az üres soroktól.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: pandas.DataFrame\n",
    "        Az adatbázisból készített DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A megtisztított adatbázis.\n",
    "    \"\"\"\n",
    "\n",
    "    ids_to_delete = dataset.index[dataset[TEXT] == ' '].tolist()\n",
    "    return dataset.drop(ids_to_delete)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Adatok előkészítése\n",
    "\n",
    "dataset = pd.read_csv('db/sport_or_e_sport.csv', sep=';', error_bad_lines=False)\n",
    "dataset = shuffle(dataset, random_state=SHUFFLE_RANDOM_STATE)\n",
    "dataset.info()\n",
    "\n",
    "dataset = delete_empty_rows(dataset)\n",
    "for i  in range(len(dataset.index)):\n",
    "    dataset[TEXT].iloc[i] = cleanse(i)\n",
    "\n",
    "dataset = delete_empty_rows(dataset)\n",
    "dataset.head(5)\n",
    "X = dataset[TEXT].values\n",
    "y = dataset[Y_HEADER].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=TRAIN_RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Adatok vizualizálása\n",
    "\n",
    "def plot_label_counts(y, title='y labels'):\n",
    "    \"\"\"\n",
    "    Adatok eloszlásának ábrázolása.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: numpy.ndarray\n",
    "        Az adathalmaz címkéi, amelyre a vizualizálás történik.\n",
    "    title: str\n",
    "        Az elkészített ábra címe.\n",
    "    \"\"\"\n",
    "\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    b = dict(zip(unique, counts))\n",
    "    b_values = [b['SPORT'], b['VIDEÓJÁTÉK']]\n",
    "    plt.barh(range(len(b)), b_values, align='center', color=['lightblue', 'lightgreen'])\n",
    "    y_values = [\"Sport\", \"Videójáték\"]\n",
    "    y_axis = np.arange(0, 2, 1)\n",
    "    plt.yticks(y_axis, y_values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of Samples in training Set')\n",
    "    plt.ylabel('Label')\n",
    "    ax = plt.gca()\n",
    "    for i, v in enumerate(b_values):\n",
    "        plt.text(ax.get_xlim()[1]/100, i, str(v), color='blue', fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "plot_label_counts(y_train, 'Train eloszlas')\n",
    "plot_label_counts(y_test, 'Test eloszlas')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(predict, labels):\n",
    "    \"\"\"\n",
    "    A modell kiértékelése. Kiíratja az osztályozási eredményeket, a pontosságot, illetve az igazságmátrixot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predict: numpy.ndarray\n",
    "        A modell predikcióit tartalmazza a teszt adathalmazra.\n",
    "    y: numpy.ndarray\n",
    "        A teszt adathalmaz címkéit tartalmazza.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Classification report:')\n",
    "    print(classification_report(labels, predict))\n",
    "    print('Accuracy:')\n",
    "    print(accuracy_score(labels, predict))\n",
    "\n",
    "    print('Confusion matrix:')\n",
    "    df_cm = pd.DataFrame(confusion_matrix(labels, predict, labels=['SPORT', 'VIDEÓJÁTÉK']),\n",
    "                         index=[i for i in ['SPORT', 'VIDEÓJÁTÉK']],\n",
    "                         columns=[i for i in ['SPORT', 'VIDEÓJÁTÉK']])\n",
    "    plt.figure(figsize=(10,7))\n",
    "    hm = sn.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\n",
    "    hm.set(ylabel='True label', xlabel='Predicted label')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Stop word-ök letöltése\n",
    "\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Korpuszok létrehozása a dokumentumokból\n",
    "\n",
    "all_stopwords = []\n",
    "\n",
    "def create_corpus_by_dataset(sentences):\n",
    "    \"\"\"\n",
    "    Korpusz létrehozása. Stop word-ök és stemmelés alkalmazása, amennyiben azok engedélyezve vannak.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences: list of numpy.ndarray\n",
    "        Az adathalmazban található dokumentumokat tartalmazó lista, amelyen a stop word-ök alkalmazva lesznek.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        Az elkészített korpusz.\n",
    "    \"\"\"\n",
    "\n",
    "    global all_stopwords\n",
    "    corpus = []\n",
    "    for sen in sentences:\n",
    "        if USE_STOPWORDS:\n",
    "            all_stopwords = stopwords.words('hungarian')\n",
    "            whitelist = [\"ne\", \"nem\", \"se\", \"sem\"]\n",
    "            sentence = [word for word in sen.split() if (word not in all_stopwords or word in whitelist)\n",
    "                 and len(word) > 1]\n",
    "        if USE_STEM:\n",
    "            ps = SnowballStemmer('hungarian')\n",
    "            sentence = [ps.stem(word) for word in sentence]\n",
    "        sentence = ' '.join(sentence)\n",
    "        corpus.append(sentence)\n",
    "\n",
    "    return corpus\n",
    "\n",
    "X_train_clean = create_corpus_by_dataset(X_train)\n",
    "X_test_clean = create_corpus_by_dataset(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bag of words modell létrehozása és illesztése\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.002, ngram_range=(1,3))\n",
    "x_train_model = cv.fit_transform(X_train_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SGD osztályozó létrehozása és illesztése\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(random_state=SGD_RANDOM_STATE, learning_rate='constant',\n",
    "                           eta0=0.01)\n",
    "classifier.fit(x_train_model, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Beállított modellek kiértékelése\n",
    "\n",
    "x_dev_model = cv.transform(X_test_clean)\n",
    "\n",
    "dev_predict = classifier.predict(x_dev_model)\n",
    "\n",
    "evaluate(dev_predict, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grid Search előkészítése és illesztése\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "           ('vect', cv),\n",
    "           ('clf', classifier)\n",
    "])\n",
    "\n",
    "parameters_to_tune = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__min_df': (0.001, 0.002, 0.005, 0.01),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "    'clf__max_iter': (500, 1000, 2000, 5000),\n",
    "    'clf__eta0': (0.005, 0.01, 0.02, 0.05)\n",
    "}\n",
    "clf=GridSearchCV(pipeline,parameters_to_tune, n_jobs=-1, verbose=1)\n",
    "clf.fit(X_train_clean, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optimális hiperparaméterekkel beállított modellek részleteinek kiírása\n",
    "\n",
    "print(clf.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predikálás az optimális hiperparaméterekkel beállított modelleken\n",
    "\n",
    "pred2 = clf.predict(X_test_clean)\n",
    "evaluate(pred2, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}